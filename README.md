# CODSOFT_DATA-SCIENCE
Author: DEBJEET PALIT

This file consists of four tasks and every task is performed with the below mentioned objective.

TASK 1: TITANIC SURVIVAL PREDICTION

Using the Titanic dataset to build a model that predicts whether a passenger on the Titanic survived or not.
The dataset typically used for this project contains information about individual passengers, such as their age, gender, ticket class, fare, cabin, and whether or not they survived.

Task 3: IRIS FLOWER CLASSIFICATION

The Iris flower dataset consists of three species: setosa, versicolor, and virginica. These species can be distinguished based on their measurements. Now, imagine that we have the measurements of Iris flowers categorized by their respective species.
Our objective is to develop a machine learning model to classify Iris flowers into species based on sepal and petal measurements. This involves loading the dataset, exploring it, preprocessing the data, training a model, that can classify irisflowers into different species based on their sepal and petal
measurements.

Task 4: SALES PREDICTION USING PYTHON

Sales prediction involves forecasting the amount of a product that customers will purchase, taking into account various factors such as advertising expenditure, target audience segmentation, and advertising platform selection.
In businesses that offer products or services, the role of a Data Scientist is crucial for predicting future sales. 
They utilization of machine learning techniques in Python to analyze and interpret data, allowing them to make informed decisions regarding advertising costs. By leveraging these predictions, businesses can optimize their advertising strategies and maximize sales potential.
The dataset typically used for this project contains information about items like TV, Radio, Newspaper and their respective Sales.

Task 5: CREDIT CARD FRAUD DETECTION

Building a machine learning model to identify fraudulent credit card transactions.
Preprocess and normalize the transaction data, handle class imbalance issues, and split the dataset into training and testing sets.
Train a classification algorithm, such as logistic regression or randomforests, to classify transactions as fraudulent or genuine.
'Evaluate the model's performance using metrics like precision, recall, and F1-score, and considering techniques like oversampling or undersampling for improving results.
